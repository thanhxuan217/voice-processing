from xml.etree.ElementTree import Element, SubElement, ElementTree
import whisperx
import torch
from lxml import etree
import json

LANG = "vi"
compute_type = "float16"

try:
    device = "cuda" if torch.cuda.is_available() else "cpu"
except Exception:
    device = "cpu"
print(f"ğŸ”„ Äang cháº¡y trÃªn device={device}...")

def alignment(audio_path, output_path):
    # 1) Load transcription model vÃ  transcribe
    print("ğŸ”„ Äang load model transcription vÃ  thá»±c hiá»‡n transcription...")
    model = whisperx.load_model("turbo", device=device, compute_type=compute_type, language=LANG)
    result = model.transcribe(audio_path, language=LANG)
    print(f"âœ… Transcription xong: {len(result.get('segments', []))} segments")

    # 2) Load align model vÃ  align
    print("ğŸ”„ Äang load model align...")
    model_a, metadata = whisperx.load_align_model(language_code=LANG, device=device)

    print("ğŸ”„ Äang thá»±c hiá»‡n forced alignment vá»›i transcript tá»« WhisperX...")
    aligned_result = whisperx.align(result["segments"], model_a, metadata, audio_path, device)
    print(f"âœ… HoÃ n thÃ nh alignment. CÃ³ {len(aligned_result.get('segments', []))} Ä‘oáº¡n.")

    # 3) Xuáº¥t káº¿t quáº£ alignment ra JSON (tÆ°Æ¡ng thÃ­ch UTF-8)
    export_data = {
        "transcription_model": "turbo",
        "device": device,
        "audio_file": audio_path,
        "segments": aligned_result.get("segments"),
        # má»™t sá»‘ phiÃªn báº£n whisperx tráº£ vá» word-level dÆ°á»›i key khÃ¡c nhau; gá»“m cáº£ Ä‘á»ƒ an toÃ n
        "word_segments": aligned_result.get("word_segments") or aligned_result.get("words") or aligned_result.get("tokens")
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

    print(f"âœ… ÄÃ£ xuáº¥t káº¿t quáº£ alignment: {output_path}")
