from xml.etree.ElementTree import Element, SubElement, ElementTree
import whisperx
import torch
from lxml import etree
import os
import json


LANG = "vi"
AUDIO_FILE = "audio/6375-bo-sach-canh-dieu-ngu-van-lop-6-tap-hai.mp3"
OUTPUT_JSON = "ngu_van_aligned_result.json"
compute_type = "float16"

try:
    device = "cuda" if torch.cuda.is_available() else "cpu"
except Exception:
    device = "cpu"
print(f"ğŸ”„ Äang cháº¡y trÃªn device={device}...")

# 1) Load transcription model vÃ  transcribe
print("ğŸ”„ Äang load model transcription vÃ  thá»±c hiá»‡n transcription...")
model = whisperx.load_model("turbo", device=device, compute_type=compute_type, language=LANG)
result = model.transcribe(AUDIO_FILE, language=LANG)
print(f"âœ… Transcription xong: {len(result.get('segments', []))} segments")

# 2) Load align model vÃ  align
print("ğŸ”„ Äang load model align...")
model_a, metadata = whisperx.load_align_model(language_code=LANG, device=device)

print("ğŸ”„ Äang thá»±c hiá»‡n forced alignment vá»›i transcript tá»« WhisperX...")
aligned_result = whisperx.align(result["segments"], model_a, metadata, AUDIO_FILE, device)
print(f"âœ… HoÃ n thÃ nh alignment. CÃ³ {len(aligned_result.get('segments', []))} Ä‘oáº¡n.")

# 3) Xuáº¥t káº¿t quáº£ alignment ra JSON (tÆ°Æ¡ng thÃ­ch UTF-8)
export_data = {
    "transcription_model": "turbo",
    "device": device,
    "audio_file": AUDIO_FILE,
    "segments": aligned_result.get("segments"),
    # má»™t sá»‘ phiÃªn báº£n whisperx tráº£ vá» word-level dÆ°á»›i key khÃ¡c nhau; gá»“m cáº£ Ä‘á»ƒ an toÃ n
    "word_segments": aligned_result.get("word_segments") or aligned_result.get("words") or aligned_result.get("tokens")
}

with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

print(f"âœ… ÄÃ£ xuáº¥t káº¿t quáº£ alignment: {OUTPUT_JSON}")
